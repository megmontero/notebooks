{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Seleccionamos la ColecciÃ³n y definimos el rango en el que queremos trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pymongo import MongoClient\n",
    "import time\n",
    "import operator\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.twitter\n",
    "te = db['prueba2']\n",
    "inicio =  datetime.datetime(2017, 4, 14)\n",
    "fin = datetime.datetime(2017,4,15)\n",
    "limit = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Creamos un diccionario por URLS y metemos primera fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dw = defaultdict(lambda: [0, datetime.datetime.now()])\n",
    "for a in te.find({'$and': [{'created_at': {\"$lt\" : fin}} ,{'created_at': {\"$gt\" : inicio}} ]}):\n",
    "    if len(a['entities']['urls']) >0:\n",
    "        for b in a['entities']['urls']:\n",
    "            if dw[b['expanded_url']]:\n",
    "                dw[b['expanded_url']][0] += 1\n",
    "                if(a['created_at'] < dw[b['expanded_url']][1]):\n",
    "                    dw[b['expanded_url']][1]= a['created_at']\n",
    "    if 'retweeted_status' in a and len(a['retweeted_status']['entities']['urls']) >0:      \n",
    "        for b in a['retweeted_status']['entities']['urls']:\n",
    "                dw[b['expanded_url']][0] +=  1\n",
    "                if(a['created_at'] < dw[b['expanded_url']][1]):\n",
    "                    dw[b['expanded_url']][1]= a['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Creamos lista ordenada a partir del diccionario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print dw\n",
    "lista = map (lambda (x,y): [x,y[0],y[1]],dw.items())\n",
    "trending = sorted(lista, key=operator.itemgetter(1), reverse=True)\n",
    "#print trending\n",
    "i = 1\n",
    "#trending = []\n",
    "urls = [] \n",
    "medias = ['elpais', 'elmundo', 'eleconomista', 'elmundotoday', 'marca com', '20minutos', 'meneame', 'quora']\n",
    "for a in trending:\n",
    "    if any(word in str(a[0]) for word in medias):\n",
    "        urls.append(a)\n",
    "        i = i+1\n",
    "    if i > limit:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Analizamos la info de las urls extraidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_data_pais(name):\n",
    "    opener = urllib2.build_opener()\n",
    "    opener.addheaders = [('User-Agent', 'Mozilla/5.0')]\n",
    "    webpage = opener.open(name).read()\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    title = soup.find(\"meta\",  property=\"og:title\")\n",
    "    title2 = soup.find(\"meta\",  {\"name\":\"title\"})\n",
    "    title3 = soup.find(\"title\")\n",
    "    url = soup.find(\"meta\",  property=\"og:url\")\n",
    "    desc = soup.find(\"meta\",  property=\"og:description\")\n",
    "    desc2 = soup.find(\"meta\",  {\"name\":\"description\"})\n",
    "    img = soup.find(\"meta\",  property=\"og:image\")\n",
    "    d = {}\n",
    "    if title3 :\n",
    "            title3= str(title3).replace(\"<title>\", \"\").replace(\"</title>\", \"\")\n",
    "    d['title'] = title[\"content\"] if title else (title2[\"content\"] if title2 else title3)\n",
    "    d['url'] = url[\"content\"] if url else name\n",
    "    d[\"desc\"] = desc[\"content\"] if desc else (desc2[\"content\"] if desc2 else None)\n",
    "    d[\"img\"] = img[\"content\"] if img else None\n",
    "    \n",
    "    if not d[\"img\"]:\n",
    "        imgs = soup.findAll(\"div\", {\"class\":\"article-image\"})\n",
    "        for img in imgs:\n",
    "            soup2 = BeautifulSoup(str(img), 'html.parser')\n",
    "            i = soup2.findAll(\"img\")\n",
    "            if i:\n",
    "                i = str(i)[str(i).index('src=\"')+5:]\n",
    "                i = i[:i.index('\"')]\n",
    "                d[\"img\"] = i\n",
    "    \n",
    "    \n",
    "    return d\n",
    "  \n",
    "lurls = []\n",
    "#urls = [[r'http://m.20minutos.es/deportes/noticia/der-spiegel-cristiano-ronaldo-pago-euros-evitar-juicio-presunta-violacion-3012042/0/',4]]\n",
    "\n",
    "\n",
    "\n",
    "for url in urls:\n",
    "    d = get_data_pais(url[0])\n",
    "    d['rank'] = url[1]\n",
    "    lurls.append(d)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for d in lurls:\n",
    "    if not d['title']:\n",
    "        print d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Volcamos a json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('tweevy', 'w') as f:\n",
    "    f.write(json.dumps(lurls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
